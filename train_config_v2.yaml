# Training config v2 - Contrastive Loss Trainer
# Curriculum mining: random → semi-hard → hard

training:
  max_epochs: 50
  patience: 15  # Early stopping patience

optimizer:
  learning_rate: 5.0e-4
  weight_decay: 1.0e-5
  lr_scheduler_factor: 0.5
  lr_scheduler_patience: 5

loss:
  margin: 1.2  # Contrastive loss margin

# Curriculum mining: 3 fasi
mining:
  random_epochs: 5      # Epoch 1-10: random mining
  semihard_epochs: 15     # Epoch 11-25: semi-hard mining
  hardmining_epochs: 50  # Epoch 26-100: hard mining

# PK sampling per batch
batch:
  num_patients: 64  # P: numero pazienti per batch
  num_ecg: 4        # K: numero ECG per paziente
  # Batch size = 64 * 4 = 256

encoder:
  input_dim: 13
  hidden_dims: [32, 64]
  embedding_dim: 64
  dropout: 0.2
  normalize: true

data:
  # Path relativi rispetto alla directory del progetto
  train_csv: data/ECG/train.csv
  val_csv: data/ECG/val.csv
  test_csv : data/ECG/test.csv

device: cuda
